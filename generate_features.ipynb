{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generate_features.ipynb","provenance":[],"authorship_tag":"ABX9TyMjiPR1kgTHaJX1aTE0PdS2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nGzW7OEsiChk"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FPEx0PgTk5YK"},"source":["# cd drive/MyDrive/product_recommender_system"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"otc_lWyCkKic"},"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.layers import Input\n","import numpy as np\n","import pickle\n","import glob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N98EEsL7iW8G"},"source":["def process_inputs(img_path):\n","  img = image.load_img(img_path, target_size=(100, 100))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","  x = preprocess_input(x)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWKWIfJQipe3","executionInfo":{"status":"ok","timestamp":1612457343900,"user_tz":-360,"elapsed":574420,"user":{"displayName":"Md. Nurul Islam Nahid","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjVk0stHnqruJSUXnlFLcBFvZIUg8bG_adY5Wp=s64","userId":"15265559200288770799"}},"outputId":"8556201b-c50b-4057-84d3-ce9ae6ccc44b"},"source":["data_dir = 'dataset'\n","features = {}\n","images = glob.glob(data_dir + '/*/*/*/*.jpg')\n","model = VGG16(weights='imagenet', input_tensor=Input(shape=(100,100,3)), include_top=False)\n","print(\"Feature vectorization start\")\n","for i, image_path in enumerate(images):\n","  img = process_inputs(image_path)\n","  feature = model.predict(img)\n","  feature = feature.flatten()/np.linalg.norm(feature)\n","  features[image_path] = feature\n","  if (i+1)%50==0:\n","    print(\"{} images completed.\".format(i+1))\n","print(\"Feature vectorization   Finished\")\n","with open('features.pickle', 'wb') as ff:\n","  pickle.dump(features, ff)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Feature vectorization start\n","50 images completed.\n","100 images completed.\n","150 images completed.\n","200 images completed.\n","250 images completed.\n","300 images completed.\n","350 images completed.\n","400 images completed.\n","450 images completed.\n","500 images completed.\n","550 images completed.\n","600 images completed.\n","650 images completed.\n","700 images completed.\n","750 images completed.\n","800 images completed.\n","850 images completed.\n","900 images completed.\n","950 images completed.\n","1000 images completed.\n","1050 images completed.\n","1100 images completed.\n","1150 images completed.\n","1200 images completed.\n","1250 images completed.\n","1300 images completed.\n","1350 images completed.\n","1400 images completed.\n","1450 images completed.\n","1500 images completed.\n","1550 images completed.\n","1600 images completed.\n","1650 images completed.\n","1700 images completed.\n","1750 images completed.\n","1800 images completed.\n","1850 images completed.\n","1900 images completed.\n","1950 images completed.\n","2000 images completed.\n","2050 images completed.\n","2100 images completed.\n","2150 images completed.\n","2200 images completed.\n","2250 images completed.\n","2300 images completed.\n","2350 images completed.\n","2400 images completed.\n","2450 images completed.\n","2500 images completed.\n","2550 images completed.\n","2600 images completed.\n","2650 images completed.\n","2700 images completed.\n","2750 images completed.\n","2800 images completed.\n","2850 images completed.\n","2900 images completed.\n","2950 images completed.\n","3000 images completed.\n","3050 images completed.\n","3100 images completed.\n","3150 images completed.\n","3200 images completed.\n","3250 images completed.\n","3300 images completed.\n","3350 images completed.\n","3400 images completed.\n","3450 images completed.\n","3500 images completed.\n","Feature vectorization   Finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eF-81N2lt799"},"source":["# import time\n","# st= time.time()\n","# data_feature = pickle.load(open('features.pickle', 'rb'))\n","# print(time.time()-st)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxD66VDylz3A"},"source":[""],"execution_count":null,"outputs":[]}]}